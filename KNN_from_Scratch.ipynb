{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "üß† Explanation (for Notebook)\n",
        "üîπ What is KNN?\n",
        "\n",
        "K-Nearest Neighbors (KNN) is a simple supervised learning algorithm used for classification (and sometimes regression).\n",
        "It predicts the label of a new data point by looking at the K closest samples in the training data.\n",
        "\n",
        "‚öôÔ∏è How it Works (Step-by-Step)\n",
        "\n",
        "1Ô∏è‚É£ Store the data\n",
        "Unlike other algorithms, KNN doesn‚Äôt ‚Äúlearn‚Äù during training.\n",
        "It just stores the dataset in memory (this is why it‚Äôs called a lazy learner).\n",
        "\n",
        "2Ô∏è‚É£ Measure distances\n",
        "When we predict for a new sample, the algorithm calculates the Euclidean distance between the test point and all training points:\n",
        "\n",
        "distance = ‚àö((x‚ÇÅ - x‚ÇÇ)¬≤ + (y‚ÇÅ - y‚ÇÇ)¬≤ + ... )\n",
        "\n",
        "\n",
        "3Ô∏è‚É£ Find nearest neighbors\n",
        "It then picks the K smallest distances ‚Äî i.e., the closest points in the dataset.\n",
        "\n",
        "4Ô∏è‚É£ Majority voting\n",
        "Among those K neighbors, the algorithm checks which label appears most frequently and assigns that label to the new sample.\n",
        "\n",
        "üí° Key Intuition\n",
        "\n",
        "KNN assumes that similar data points exist close to each other in space.\n",
        "So, if most of your nearby samples belong to class ‚ÄúA‚Äù, your new sample is probably ‚ÄúA‚Äù too.\n",
        "\n",
        "üöÄ Example Use Case\n",
        "\n",
        "If you have labeled data (e.g., images of cats üê± and dogs üê∂),\n",
        "KNN can classify a new image by checking which category its closest neighbors belong to.\n",
        "\n",
        "‚úÖ In short:\n",
        "KNN doesn‚Äôt build a model ‚Äî it relies purely on distance and similarity, making it one of the most intuitive ML algorithms to understand and implement."
      ],
      "metadata": {
        "id": "Obv-xoLF_dpn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lX_w_UqC_biB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "class KNN:\n",
        "    def __init__(self, k=3):\n",
        "        # Number of neighbors to consider\n",
        "        self.k = k\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        # Just store the training data ‚Äî KNN is a lazy learner\n",
        "        self.X_train = X\n",
        "        self.y_train = y\n",
        "\n",
        "    def predict(self, X):\n",
        "        # Predict labels for all test samples\n",
        "        predictions = [self._predict(x) for x in X]\n",
        "        return np.array(predictions)\n",
        "\n",
        "    def _predict(self, x):\n",
        "        # Compute Euclidean distances between x and all training samples\n",
        "        distances = [np.linalg.norm(x - x_train) for x_train in self.X_train]\n",
        "        # Get the indices of the k nearest neighbors\n",
        "        k_indices = np.argsort(distances)[:self.k]\n",
        "        # Get the labels of those neighbors\n",
        "        k_nearest_labels = [self.y_train[i] for i in k_indices]\n",
        "        # Return the most common label (majority vote)\n",
        "        most_common = Counter(k_nearest_labels).most_common(1)\n",
        "        return most_common[0][0]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Simple Test for KNN ---\n",
        "\n",
        "# Sample dataset (X: features, y: labels)\n",
        "X_train = np.array([\n",
        "    [1, 2],\n",
        "    [2, 3],\n",
        "    [3, 4],\n",
        "    [6, 7],\n",
        "    [7, 8],\n",
        "    [8, 9]\n",
        "])\n",
        "y_train = np.array([0, 0, 0, 1, 1, 1])  # 0 and 1 are the two classes\n",
        "\n",
        "# Initialize and fit the model\n",
        "model = KNN(k=3)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Test points\n",
        "X_test = np.array([\n",
        "    [2, 3],  # closer to class 0\n",
        "    [7, 7]   # closer to class 1\n",
        "])\n",
        "\n",
        "# Predict\n",
        "predictions = model.predict(X_test)\n",
        "print(\"Predictions:\", predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVH9o1qr_cZC",
        "outputId": "b9e16f25-918e-43d0-cf97-0ec5def1075a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions: [0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9CADIeNG_o14"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}